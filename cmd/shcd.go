/*
Copyright 2021 Hewlett Packard Enterprise Development LP
*/

package cmd

import (
	"encoding/csv"
	"encoding/json"
	"fmt"
	"io/ioutil"
	"log"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"
	"unicode"

	"github.com/Cray-HPE/cray-site-init/pkg/csi"
	"github.com/spf13/cobra"
	"github.com/spf13/viper"
	"github.com/xeipuuv/gojsonschema"
	"gopkg.in/yaml.v3"
)

const schema = "shcd-schema.json"
const hmn_connections = "hmn_connections.json"
const switch_metadata = "switch_metadata.csv"
const application_node_config = "application_node_config.yaml"

var createHMN, createSM, createANC bool

var prefixSubroleMapIn map[string]string

var schemaFile, customSchema string

// initCmd represents the init command
var shcdCmd = &cobra.Command{
	Use:   "shcd FILEPATH",
	Short: "Generates hmn_connections.json, switch_metadata.csv, and application_node_config.yaml from an SHCD JSON file",
	Long: `Generates hmn_connections.json, switch_metadata.csv, application_node_config.yaml from an SHCD JSON file.

	It accepts only a valid JSON file, generated by 'canu', which is creates a machine-
	readable format understood by csi.  It is checked against a pre-defined schema and
	if it adhere's to it, it generates the necessary seed files.
	`,
	Args: cobra.MinimumNArgs(1),
	Run: func(cmd *cobra.Command, args []string) {
		v := viper.GetViper()
		v.BindPFlags(cmd.Flags())

		if v.IsSet("schema-file") {
			schemaFile = customSchema
		} else {
			schemaFile = filepath.Join("internal/files/", schema)
		}

		// Validate the file passed against the pre-defined schema
		validSHCD, err := ValidateSchema(args[0], schemaFile)

		if err != nil {
			log.Fatalf(err.Error())
		}

		// If the file meets the schema criteria
		if validSHCD {

			// Open the file since we know it is valid
			shcdFile, err := ioutil.ReadFile(args[0])

			if err != nil {
				log.Fatalf(err.Error())
			}

			// Parse the JSON and return an Shcd object
			s, err := ParseSHCD(shcdFile)

			if err != nil {
				log.Fatalf(err.Error())
			}

			if v.IsSet("hmn-connections") {

				createHMNSeed(s, hmn_connections)

			}

			if v.IsSet("switch-metadata") {

				createSwitchSeed(s, switch_metadata)

			}

			if v.IsSet("application-node-config") {

				createANCSeed(s, application_node_config)

			}

		} else {

			log.Printf("- %s\n", err)

			if err != nil {
				log.Fatalf(err.Error())
			}

		}
	},
}

func init() {
	shcdCmd.DisableAutoGenTag = true
	shcdCmd.Flags().SortFlags = true
	shcdCmd.Flags().StringVarP(&customSchema, "schema-file", "j", "", "Use a custom schema file")
	shcdCmd.Flags().BoolVarP(&createHMN, "hmn-connections", "H", false, "Generate the hmn_connections.json file")
	shcdCmd.Flags().BoolVarP(&createSM, "switch-metadata", "S", false, "Generate the switch_metadata.csv file")
	shcdCmd.Flags().BoolVarP(&createANC, "application-node-config", "A", false, "Generate the application_node_config.yaml file")
	shcdCmd.Flags().StringToStringVarP(&prefixSubroleMapIn, "prefix-subrole-mapping", "M", map[string]string{}, "Specify one or more additional <Prefix>=<Subrole> mappings to use when generating application_node_config.yaml. Multiple mappings can be specified in the format of <prefix1>=<subrole1>,<prefix2>=<subrole2>")
}

// The Shcd type represents the entire machine-readable SHCD inside a go struct
type Shcd []Id

// The Id type represents all of the information needed for
type Id struct {
	Architecture string   `json:"architecture"`
	CommonName   string   `json:"common_name"`
	ID           int      `json:"id"`
	Location     Location `json:"location"`
	Model        string   `json:"model"`
	Ports        []Port   `json:"ports"`
	Type         string   `json:"type"`
	Vendor       string   `json:"vendor"`
}

// The Port type defines where things are plugged in
type Port struct {
	DestNodeID int    `json:"destination_node_id"`
	DestPort   int    `json:"destination_port"`
	DestSlot   string `json:"destination_slot"`
	Port       int    `json:"port"`
	Slot       string `json:"slot"`
	Speed      int    `json:"speed"`
}

type Location struct {
	Elevation string `json:"elevation"`
	Rack      string `json:"rack"`
}

// HMNConnections type is the go equivalent structure of hmn_connections.json
type HMNConnections []HMNComponent

// HMNComponent is an individual component in the HMNConnections slice
type HMNComponent struct {
	Source              string `json:"Source"`
	SourceRack          string `json:"SourceRack"`
	SourceLocation      string `json:"SourceLocation"`
	SourceParent        string `json:"SourceParent,omitempty"`
	SourceSubLocation   string `json:"SourceSubLocation,omitempty"`
	DestinationRack     string `json:"DestinationRack"`
	DestinationLocation string `json:"DestinationLocation"`
	DestinationPort     string `json:"DestinationPort"`
}

// SwitchMetadata type is the go equivalent structure of switch_metadata.csv
type SwitchMetadata []Switch

// Switch is a row in switch_metadata.csv
type Switch struct {
	Xname string
	Type  string
	Brand string
}

// Crafts and prints the switch types that switch_metadata.csv expects
func (id Id) GenerateSwitchType() (st string) {

	// The switch type in switch_metadata.csv differs from the types in the SHCD
	// These conditionals just adjust for the names we expect in that file
	if strings.Contains(id.Architecture, "bmc") {

		st = "Leaf"

	} else if strings.Contains(id.Architecture, "spine") {

		st = "Spine"

	} else if strings.Contains(id.Architecture, "river_ncn_leaf") {

		st = "Aggregation"

	} else if strings.Contains(id.CommonName, "cdu") {

		st = "CDU"
	}

	// Return the switch type switch_metadata.csv is expecting
	return st
}

// Crafts and prints the switch types that switch_metadata.csv expects
func (id Id) GenerateHMNSourceName() (src string) {

	// var prefix string

	// The Source in hmn_connections.json differs from the common_name in the SHCD
	// These conditionals just adjust for the names we expect in that file
	if strings.HasPrefix(id.CommonName, "ncn-m") ||
		strings.HasPrefix(id.CommonName, "ncn-s") ||
		strings.HasPrefix(id.CommonName, "ncn-w") ||
		strings.HasPrefix(id.CommonName, "uan") ||
		strings.HasPrefix(id.CommonName, "cn") ||
		strings.HasPrefix(id.CommonName, "sw-hsn") ||
		strings.HasPrefix(id.CommonName, "x3000p") ||
		strings.HasPrefix(id.CommonName, "lnet") {

		// Get the just number of the elevation
		r := regexp.MustCompile(`\d+`)

		// matches contains the numbers found in the common name
		matches := r.FindAllString(id.CommonName, -1)

		if strings.HasPrefix(id.CommonName, "uan") {

			// if it's a uan, print "uan" and the number
			src = string(id.CommonName[0:3]) + matches[0]

		} else if strings.HasPrefix(id.CommonName, "cn") {

			// if it's a compute node, print "cn" and the number
			src = string(id.CommonName[0:2]) + matches[0]

		} else if strings.HasPrefix(id.CommonName, "lnet") {

			// if it's an lnet, print "lnet" and the number
			src = string(id.CommonName[0:4]) + matches[0]

		} else if strings.HasPrefix(id.CommonName, "x3000p") {

			// if it's a pdu, print the entire name
			src = string(id.CommonName)

		} else if strings.HasPrefix(id.CommonName, "sw-hsn") {

			// if it's a hsn switch, print the entire name
			src = string(id.CommonName)

		} else {

			// if nothing else matches, return an empty string
			src = ""

		}
	}

	// Return the Source name hmn_connections.json is expecting
	return src
}

// createSwitchSeed creates switch_metadata.csv using information from the shcd
func createSwitchSeed(shcd Shcd, f string) {
	var switches SwitchMetadata

	// For each entry in the SHCD
	for i := range shcd {

		// Create a new Switch type and append it to the SwitchMetadata slice
		switches = append(switches, Switch{
			Xname: shcd[i].Location.Rack,
			Type:  shcd[i].Type,
			Brand: shcd[i].Vendor,
		})

	}

	// When writing to csv, the first row should be the headers
	headers := []string{"Switch Xname", "Type", "Brand"}

	// Set up the records we need to write to the file
	// To begin, this contains the headers
	records := [][]string{headers}

	// Then create a new slice with the three pieces of information needed
	for _, v := range switches {
		row := []string{v.Xname, v.Type, v.Brand}
		// Append it to the records slice under the column headers
		records = append(records, row)
	}

	// Create the file object
	sm, err := os.Create(switch_metadata)

	if err != nil {
		log.Fatalln(err)
	}

	defer sm.Close()

	// Create a writer, which will write the data to the file
	writer := csv.NewWriter(sm)

	defer writer.Flush()

	if err != nil {
		log.Fatalln(err)
	}

	// For each item in the records slice
	for _, v := range records {
		// Write it to the csv file
		if err := writer.Write(v); err != nil {
			log.Fatalln(err)
		}
	}

	// Let the user know the file was created
	log.Printf("Created %v from SHCD data\n", switch_metadata)
}

// createHMNSeed creates hmn_connections.json using information from the shcd
func createHMNSeed(shcd Shcd, f string) {

	var hmn HMNConnections

	// For each entry in the shcd
	for i := range shcd {

		// instantiate a new HMNComponent
		hmnConnection := HMNComponent{}

		// This just aligns the names to better match existing hmn_connections.json's
		// The SHCD and shcd.json all use different names, so why should csi be any different?
		// nodeName := unNormalizeSemiStandardShcdNonName(shcd[i].CommonName)

		// Setting the source name, source rack, source location, is pretty straightforward here
		hmnConnection.Source = shcd[i].CommonName
		hmnConnection.SourceRack = shcd[i].Location.Rack
		hmnConnection.SourceLocation = shcd[i].Location.Elevation

		// Now it starts to get more complex.
		// shcd.json has an array of ports that the device is connected to
		// loop through the ports and find the destination id, which can be used
		// to find the destination info
		for p := range shcd[i].Ports {
			// get the id of the destination node, so it can be easily used an an index
			destId := shcd[i].Ports[p].DestNodeID
			// Special to this hmn_connections.json file, we need this SubRack/dense node stuff
			// if the node is a dense compute node--indiciated by L or R in the location,
			// we need to add the SourceSubLocation and SourceParent
			// There should be a row in the shcd that has the SubRack name, which
			// shares the same u location as the entries with the L or R in the location
			if strings.HasSuffix(shcd[i].Location.Elevation, "L") || strings.HasSuffix(shcd[i].Location.Elevation, "R") {
				// hmnConnection.SourceSubLocation = shcd[i].Location.Rack
				hmnConnection.SourceParent = "FIXME INSERT SUBRACK HERE"
				// FIXME: remove above and uncomment below when we have a way to get the subrack name
				// hmnConnection.SourceParent = fmt.Sprint(shcd[destId].CommonName)
			}

			// Now use the destId again to set the destination info
			hmnConnection.DestinationRack = shcd[destId].Location.Rack
			hmnConnection.DestinationLocation = shcd[destId].Location.Elevation
			hmnConnection.DestinationPort = fmt.Sprint("j", shcd[i].Ports[p].DestPort)
		}

		// finally, append the created HMNComponent to the HMNConnections slice
		// This slice will be what is written to the file as hmn_connections.json
		hmn = append(hmn, hmnConnection)
	}

	// Indent the file for better human-readability
	file, _ := json.MarshalIndent(hmn, "", " ")

	// Write the file to disk
	_ = ioutil.WriteFile(hmn_connections, file, 0644)

	log.Printf("Created %v from SHCD data\n", hmn_connections)

}

// createANCSeed creates application_node_config.yaml using information from the shcd
func createANCSeed(shcd Shcd, f string) error {

	var (
		comment1 string = "# Additional application node prefixes to match in the hmn_connections.json file"
		comment2 string = "\n# Additional HSM SubRoles"
		comment3 string = "\n# Application Node aliases"
	)

	anc := csi.SLSGeneratorApplicationNodeConfig{
		Prefixes:          make([]string, 0, 1),
		PrefixHSMSubroles: make(map[string]string),
		Aliases:           make(map[string][]string),
	}
	prefixMap := make(map[string]string)

	// Search the shcd for Application Nodes
	for _, id := range shcd {
		source := strings.ToLower(id.CommonName)
		idType := strings.ToLower(id.Type)
		if idType != "server" ||
			strings.Contains(source, "ncn") {
			continue
		}

		found := false
		// Match custom prefix<->subrole mappings first before default ones
		if len(prefixSubroleMapIn) > 0 {
			for prefix, subrole := range prefixSubroleMapIn {
				if strings.HasPrefix(source, prefix) {
					found = true
					prefixMap[prefix] = subrole
					break
				}
			}
		}
		if !found {
			// Match default prefix<->subrole mappings
			for _, prefix := range csi.DefaultApplicationNodePrefixes {
				if strings.HasPrefix(source, prefix) {
					found = true
					break
				}
			}
		}

		if !found {
			// Add a placeholder for unmatched prefixes to have the admin
			// assign a subrole to use for that prefix.
			f := strings.FieldsFunc(source,
				func(c rune) bool { return !unicode.IsLetter(c) })
			prefixMap[f[0]] = "~fixme~"
		}

		location := strings.TrimFunc(id.Location.Elevation,
			func(r rune) bool { return unicode.IsLetter(r) })

		// Construct the xname
		xname := ""
		if strings.HasSuffix(strings.ToLower(id.Location.Elevation), "l") {
			xname = fmt.Sprintf("%sc0s%sb1n0", id.Location.Rack, location)
		} else if strings.HasSuffix(strings.ToLower(id.Location.Elevation), "r") {
			xname = fmt.Sprintf("%sc0s%sb2n0", id.Location.Rack, location)
		} else {
			xname = fmt.Sprintf("%sc0s%sb0n0", id.Location.Rack, location)
		}

		// List Aliases
		if _, ok := anc.Aliases[xname]; !ok {
			anc.Aliases[xname] = make([]string, 0, 1)
		}
		anc.Aliases[xname] = append(anc.Aliases[xname], source)
	}

	// Build the 'Prefixes' list and the 'PrefixHSMSubroles' map
	for prefix, subrole := range prefixMap {
		anc.Prefixes = append(anc.Prefixes, prefix)
		anc.PrefixHSMSubroles[prefix] = subrole
		// Warn the admin if there are any prefixes that have no subrole
		if subrole == csi.SubrolePlaceHolder {
			log.Printf("WARNING: Prefix '%s' has no subrole mapping. Replace `%s` placeholder with a valid subrole in the resulting %s.\n", prefix, csi.SubrolePlaceHolder, application_node_config)
		}
	}

	// Format the yaml
	prefixNodes := []*yaml.Node{}
	prefixHSMSubroleNodes := []*yaml.Node{}
	sort.Strings(anc.Prefixes)
	for _, prefix := range anc.Prefixes {
		n := yaml.Node{Kind: yaml.ScalarNode, Value: prefix}
		prefixNodes = append(prefixNodes, &n)

		subrole := anc.PrefixHSMSubroles[prefix]
		kn := yaml.Node{Kind: yaml.ScalarNode, Value: prefix}
		vn := yaml.Node{Kind: yaml.ScalarNode, Value: subrole}
		prefixHSMSubroleNodes = append(prefixHSMSubroleNodes, &kn, &vn)
	}
	prefixes := yaml.Node{Kind: yaml.SequenceNode, Content: prefixNodes}
	prefixesTitle := yaml.Node{Kind: yaml.ScalarNode, Value: "prefixes", HeadComment: comment1}
	prefixHSMSubroles := yaml.Node{Kind: yaml.MappingNode, Content: prefixHSMSubroleNodes}
	prefixHSMSubrolesTitle := yaml.Node{Kind: yaml.ScalarNode, Value: "prefix_hsm_subroles", HeadComment: comment2}

	aliasNodes := []*yaml.Node{}
	aliasArray := make([]string, 0, 1)
	for xname, _ := range anc.Aliases {
		aliasArray = append(aliasArray, xname)
	}
	sort.Strings(aliasArray)
	for _, xname := range aliasArray {
		aliasList := anc.Aliases[xname]
		kn := yaml.Node{Kind: yaml.ScalarNode, Value: xname}
		aliasSubNodes := []*yaml.Node{}
		for _, alias := range aliasList {
			n := yaml.Node{Kind: yaml.ScalarNode, Style: yaml.DoubleQuotedStyle, Value: alias}
			aliasSubNodes = append(aliasSubNodes, &n)
		}
		vn := yaml.Node{Kind: yaml.SequenceNode, Style: yaml.FlowStyle, Content: aliasSubNodes}
		aliasNodes = append(aliasNodes, &kn, &vn)
	}
	aliases := yaml.Node{Kind: yaml.MappingNode, Content: aliasNodes}
	aliasesTitle := yaml.Node{Kind: yaml.ScalarNode, Value: "aliases", HeadComment: comment3}

	ancYaml := yaml.Node{Kind: yaml.MappingNode, Content: []*yaml.Node{&prefixesTitle, &prefixes, &prefixHSMSubrolesTitle, &prefixHSMSubroles, &aliasesTitle, &aliases}}

	ancFile, err := os.Create(application_node_config)

	if err != nil {
		log.Fatalln(err)
	}
	defer ancFile.Close()
	_, err = ancFile.WriteString("---\n")
	e := yaml.NewEncoder(ancFile)
	defer e.Close()
	e.SetIndent(2)
	err = e.Encode(ancYaml)
	log.Printf("Created %v from SHCD data\n", application_node_config)
	return err
}

// ValidateSchema compares a JSON file to the defined schema file
func ValidateSchema(f string, s string) (bool, error) {
	// First validate the file passed in conforms to the schema
	schema := "file://" + s
	schemaLoader := gojsonschema.NewReferenceLoader(schema)
	jsonFile := "file://" + f
	documentLoader := gojsonschema.NewReferenceLoader(jsonFile)

	result, err := gojsonschema.Validate(schemaLoader, documentLoader)

	if err != nil {
		return false, fmt.Errorf("%s", err)
	}

	// If the json passed in does not meet the schema requirements, error
	if !result.Valid() {

		for _, desc := range result.Errors() {
			return false, fmt.Errorf("SHCD schema error: %s", desc)
		}

	}

	return true, nil
}

// ParseSHCD accepts a machine-readable SHCD and produces an Shcd object, which can be used throughout csi
// It is the golang and csi equivalent of the shcd.json file generated by canu
func ParseSHCD(f []byte) (Shcd, error) {
	var shcd Shcd

	// unmarshall it
	err := json.Unmarshal(f, &shcd)

	if err != nil {
		fmt.Println("error:", err)
		return shcd, err
	}

	return shcd, nil
}
